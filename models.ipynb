{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc7243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/mt0/24CS60R08/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/mt0/24CS60R08/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/mt0/24CS60R08/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import emoji\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import RegexpTokenizer, TweetTokenizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c1217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stopwords, lemmatizer, and tokenizer\n",
    "stop_words = set(stopwords.words('english')).union(ENGLISH_STOP_WORDS)\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()\n",
    "punct_set = set(string.punctuation + '''…'\"`’”“''' + '️')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses social media text by:\n",
    "    - Lowercasing\n",
    "    - Tokenizing using a TweetTokenizer\n",
    "    - Replacing emojis, hashtags, user mentions, and URLs with special tokens\n",
    "    - Removing punctuation and stopwords\n",
    "    - Lemmatizing tokens\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    updated_tokens = []\n",
    "    for t in tokens:\n",
    "        if emoji.is_emoji(t):\n",
    "            updated_tokens.append(f\"<emoji> {emoji.demojize(t, delimiters=('', ''))} </emoji>\")\n",
    "        elif t.startswith('#'):\n",
    "            updated_tokens.append(f'<hashtag> {t[1:]} </hashtag>')\n",
    "        elif t.startswith('@'):\n",
    "            updated_tokens.append('<user>')\n",
    "        elif t.startswith('http'):\n",
    "            updated_tokens.append('<url>')\n",
    "        elif t in punct_set:\n",
    "            pass\n",
    "        elif t and t not in stop_words:\n",
    "            updated_tokens.append(t)\n",
    "\n",
    "    updated_tokens = [lemmatizer.lemmatize(word) for word in updated_tokens]\n",
    "    return \" \".join(updated_tokens)\n",
    "\n",
    "def to_corpus(X):\n",
    "    \"\"\"Applies preprocessing to an array of text.\"\"\"\n",
    "    vfunc = np.vectorize(preprocess_text)\n",
    "    return vfunc(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a902e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class mappings and initialize the vectorizer\n",
    "class_map = {\"real\": 1, \"fake\": 0}\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"Loads, preprocesses, and vectorizes data from a CSV file.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Ensure the first column is treated as the text data\n",
    "    X = df.iloc[:, 0].values \n",
    "    y = df.iloc[:, -1].map(class_map).values\n",
    "    \n",
    "    print(\"Preprocessing text data...\")\n",
    "    X_corpus = to_corpus(X)\n",
    "    \n",
    "    print(\"Vectorizing text data with TF-IDF...\")\n",
    "    X_vectorized = vectorizer.fit_transform(X_corpus)\n",
    "    \n",
    "    return X_vectorized, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b098cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n",
      "Vectorizing text data with TF-IDF...\n",
      "\n",
      "Data loaded successfully. Shape of X: (10600, 15763), Shape of y: (10600,)\n",
      "Shape of X_train: (8480, 15763), Shape of y_train: (8480,)\n",
      "Shape of X_test:  (1060, 15763), Shape of y_test:  (1060,)\n",
      "Shape of X_val:   (1060, 15763), Shape of y_val:   (1060,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "filepath = \"./CL-II-MisinformationData - Sheet1.csv\"\n",
    "X, y = load_data(filepath)\n",
    "print(f\"\\nData loaded successfully. Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}, Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of X_test:  {X_test.shape}, Shape of y_test:  {y_test.shape}\")\n",
    "print(f\"Shape of X_val:   {X_val.shape}, Shape of y_val:   {y_val.shape}\\n\")\n",
    "\n",
    "# Dictionary to store model performance\n",
    "model_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cea44065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training K-Nearest Neighbors (KNN) ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN training completed in 4.87 seconds.\n",
      "Best parameters for KNN: {'metric': 'euclidean', 'n_neighbors': 3}\n",
      "KNN Accuracy: 0.8858\n",
      "Classification Report for KNN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88       530\n",
      "           1       0.85      0.93      0.89       530\n",
      "\n",
      "    accuracy                           0.89      1060\n",
      "   macro avg       0.89      0.89      0.89      1060\n",
      "weighted avg       0.89      0.89      0.89      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 1️. K-Nearest Neighbors (KNN) ----------------------\n",
    "print(\"--- Training K-Nearest Neighbors (KNN) ---\")\n",
    "start_time = time.time()\n",
    "knn_params = {\"n_neighbors\": [3, 5, 7], \"metric\": [\"euclidean\", \"manhattan\"]}\n",
    "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "y_pred_knn = knn_grid.best_estimator_.predict(X_test)\n",
    "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
    "model_performance[\"KNN\"] = knn_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"KNN training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters for KNN: {knn_grid.best_params_}\")\n",
    "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n",
    "print(\"Classification Report for KNN:\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5ad77b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression ---\n",
      "Logistic Regression training completed in 2.34 seconds.\n",
      "Best parameters for Logistic Regression: {'C': 10, 'solver': 'liblinear'}\n",
      "Logistic Regression Accuracy: 0.9491\n",
      "Classification Report for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       530\n",
      "           1       0.94      0.95      0.95       530\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 2. Logistic Regression ----------------------\n",
    "print(\"\\n--- Training Logistic Regression ---\")\n",
    "start_time = time.time()\n",
    "log_params = {\"C\": [0.1, 1, 10], \"solver\": [\"liblinear\"]}\n",
    "log_reg_grid = GridSearchCV(LogisticRegression(random_state=42), log_params, cv=5, n_jobs=-1)\n",
    "log_reg_grid.fit(X_train, y_train)\n",
    "y_pred_log = log_reg_grid.best_estimator_.predict(X_test)\n",
    "log_accuracy = accuracy_score(y_test, y_pred_log)\n",
    "model_performance[\"Logistic Regression\"] = log_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Logistic Regression training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters for Logistic Regression: {log_reg_grid.best_params_}\")\n",
    "print(f\"Logistic Regression Accuracy: {log_accuracy:.4f}\")\n",
    "print(\"Classification Report for Logistic Regression:\")\n",
    "print(classification_report(y_test, y_pred_log))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0daf2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Support Vector Machine (SVM) ---\n",
      "SVM training completed in 11.13 seconds.\n",
      "Best parameters for SVM: {'C': 1}\n",
      "SVM Accuracy: 0.9500\n",
      "Classification Report for SVM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       530\n",
      "           1       0.95      0.95      0.95       530\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 3️. Support Vector Machine (SVM) ----------------------\n",
    "print(\"\\n--- Training Support Vector Machine (SVM) ---\")\n",
    "start_time = time.time()\n",
    "svm_params = {\"C\": [0.1, 1, 10]}\n",
    "svm_grid = GridSearchCV(SVC(kernel=\"linear\", random_state=42), svm_params, cv=5, n_jobs=-1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "y_pred_svm = svm_grid.best_estimator_.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "model_performance[\"SVM\"] = svm_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"SVM training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters for SVM: {svm_grid.best_params_}\")\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"Classification Report for SVM:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9d3885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training K-Means Clustering ---\n",
      "K-Means cluster 0 mapped to class 0, cluster 1 to class 1.\n",
      "K-Means training completed in 0.40 seconds.\n",
      "K-Means Accuracy: 0.5896\n",
      "Classification Report for K-Means:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.86      0.68       530\n",
      "           1       0.70      0.32      0.44       530\n",
      "\n",
      "    accuracy                           0.59      1060\n",
      "   macro avg       0.63      0.59      0.56      1060\n",
      "weighted avg       0.63      0.59      0.56      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 4️. K-Means Clustering (Unsupervised) ----------------------\n",
    "print(\"\\n--- Training K-Means Clustering ---\")\n",
    "start_time = time.time()\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "kmeans.fit(X_train)\n",
    "y_pred_kmeans_raw = kmeans.predict(X_test)\n",
    "\n",
    "accuracy_mapping1 = accuracy_score(y_test, y_pred_kmeans_raw)\n",
    "accuracy_mapping2 = accuracy_score(y_test, 1 - y_pred_kmeans_raw)\n",
    "\n",
    "if accuracy_mapping1 > accuracy_mapping2:\n",
    "    kmeans_accuracy = accuracy_mapping1\n",
    "    y_pred_kmeans = y_pred_kmeans_raw\n",
    "    print(\"K-Means cluster 0 mapped to class 0, cluster 1 to class 1.\")\n",
    "else:\n",
    "    kmeans_accuracy = accuracy_mapping2\n",
    "    y_pred_kmeans = 1 - y_pred_kmeans_raw\n",
    "    print(\"K-Means cluster 0 mapped to class 1, cluster 1 to class 0.\")\n",
    "\n",
    "model_performance[\"K-Means\"] = kmeans_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"K-Means training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"K-Means Accuracy: {kmeans_accuracy:.4f}\")\n",
    "print(\"Classification Report for K-Means:\")\n",
    "print(classification_report(y_test, y_pred_kmeans))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f2d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Gradient Boosting ---\n",
      "Gradient Boosting training completed in 80.94 seconds.\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200}\n",
      "Gradient Boosting Accuracy: 0.9453\n",
      "Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       530\n",
      "           1       0.95      0.94      0.94       530\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 6️. Gradient Boosting ----------------------\n",
    "print(\"\\n--- Training Gradient Boosting ---\")\n",
    "start_time = time.time()\n",
    "gb_params = {\"n_estimators\": [100, 200], \"learning_rate\": [0.01, 0.1], \"max_depth\": [3, 5]}\n",
    "gb_grid = GridSearchCV(GradientBoostingClassifier(random_state=42), gb_params, cv=5, n_jobs=-1)\n",
    "gb_grid.fit(X_train, y_train)\n",
    "y_pred_gb = gb_grid.best_estimator_.predict(X_test)\n",
    "gb_accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "model_performance[\"Gradient Boosting\"] = gb_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Gradient Boosting training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters for Gradient Boosting: {gb_grid.best_params_}\")\n",
    "print(f\"Gradient Boosting Accuracy: {gb_accuracy:.4f}\")\n",
    "print(\"Classification Report for Gradient Boosting:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba8ddb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Neural Network (MLP) ---\n",
      "MLP training completed in 469.39 seconds.\n",
      "Best parameters for MLP: {'activation': 'tanh', 'alpha': 0.001, 'hidden_layer_sizes': (100,)}\n",
      "MLP Accuracy: 0.9481\n",
      "Classification Report for MLP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       530\n",
      "           1       0.94      0.95      0.95       530\n",
      "\n",
      "    accuracy                           0.95      1060\n",
      "   macro avg       0.95      0.95      0.95      1060\n",
      "weighted avg       0.95      0.95      0.95      1060\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- 5️. Neural Network (MLP Classifier) ----------------------\n",
    "print(\"\\n--- Training Neural Network (MLP) ---\")\n",
    "start_time = time.time()\n",
    "# Increased max_iter to 300 to ensure convergence\n",
    "mlp_params = {\"hidden_layer_sizes\": [(50,), (100,)], \"activation\": [\"relu\", \"tanh\"], \"alpha\": [0.0001, 0.001]}\n",
    "mlp_grid = GridSearchCV(MLPClassifier(max_iter=300, random_state=42), mlp_params, cv=5, n_jobs=-1)\n",
    "mlp_grid.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_grid.best_estimator_.predict(X_test)\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "model_performance[\"Neural Network\"] = mlp_accuracy\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"MLP training completed in {end_time - start_time:.2f} seconds.\")\n",
    "print(f\"Best parameters for MLP: {mlp_grid.best_params_}\")\n",
    "print(f\"MLP Accuracy: {mlp_accuracy:.4f}\")\n",
    "print(\"Classification Report for MLP:\")\n",
    "print(classification_report(y_test, y_pred_mlp))\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8edd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance (Accuracy Scores):\n",
      "\n",
      "SVM                 : 0.9500\n",
      "Logistic Regression : 0.9491\n",
      "Neural Network      : 0.9481\n",
      "Gradient Boosting   : 0.9453\n",
      "KNN                 : 0.8858\n",
      "K-Means             : 0.5896\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Final Performance Summary ----------------------\n",
    "print(\"Final Model Performance (Accuracy Scores):\\n\")\n",
    "# Sort models by accuracy in descending order\n",
    "sorted_performance = sorted(model_performance.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "for model, acc in sorted_performance:\n",
    "    print(f\"{model:<20}: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.18",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
